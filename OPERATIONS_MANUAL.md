# GKE è³‡æºæª¢æŸ¥å·¥å…·æ“ä½œæ‰‹å†Š

## ğŸ“‹ ç›®éŒ„
1. [å·¥å…·ç°¡ä»‹](#å·¥å…·ç°¡ä»‹)
2. [ç³»çµ±éœ€æ±‚](#ç³»çµ±éœ€æ±‚)
3. [å®‰è£èˆ‡é…ç½®](#å®‰è£èˆ‡é…ç½®)
4. [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
5. [å ±å‘Šè§£è®€](#å ±å‘Šè§£è®€)
6. [æ±ºç­–æŒ‡å—](#æ±ºç­–æŒ‡å—)
7. [é…ç½®èª¿æ•´](#é…ç½®èª¿æ•´)
8. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)
9. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## å·¥å…·ç°¡ä»‹

### ä»€éº¼æ˜¯ GKE æ±ºç­–å·¥å…·ï¼Ÿ

`gke_resource_check.py` æ˜¯ä¸€å€‹è‡ªå‹•åŒ–çš„ Google Kubernetes Engine (GKE) æ¶æ§‹åˆ†æå·¥å…·ï¼Œå®ƒæœƒï¼š

- ğŸ“Š **æ”¶é›†è³‡æºæ•¸æ“š**ï¼šå¾ Kubernetes é›†ç¾¤ä¸­æå–ç¯€é»å’Œ Pod è³‡æºé…ç½®
- ğŸ” **åˆ†æè² è¼‰æƒ…æ³**ï¼šè¨ˆç®— CPU å’Œè¨˜æ†¶é«”çš„ä½¿ç”¨ç‡
- ğŸ¯ **æä¾›æ±ºç­–å»ºè­°**ï¼šæ ¹æ“šé è¨­çš„é–¾å€¼ï¼Œè‡ªå‹•è­˜åˆ¥æ˜¯å¦éœ€è¦å‡ç´šæ©Ÿå‹æˆ–æ“´å……ç¯€é»
- ğŸš¨ **ç›£æ¸¬é«˜é¢¨éšª Pod**ï¼šè­˜åˆ¥å¯èƒ½å°è‡´ OOM æˆ–è³‡æºè¶…è³£çš„ Pod

### ä¸»è¦åŠŸèƒ½

| åŠŸèƒ½ | èªªæ˜ |
|------|------|
| **Pool æ±ºç­–å„€è¡¨æ¿** | é¡¯ç¤ºæ¯å€‹ Node Pool çš„å¹³å‡ CPU/è¨˜æ†¶é«”ä½¿ç”¨ç‡åŠå»ºè­°è¡Œå‹• |
| **ç¯€é»è©³ç´°æ•¸æ“š** | åˆ—å‡ºæ¯å€‹ç¯€é»çš„å¯¦æ™‚è³‡æºä½¿ç”¨æƒ…æ³å’Œé¢¨éšªç‹€æ…‹ |
| **é«˜é¢¨éšª Pod æ¸…å–®** | è­˜åˆ¥è¶…å‡ºè³‡æºé™åˆ¶æˆ–éåº¦è¶…è³£çš„ Podï¼Œå”åŠ©å„ªåŒ– |

---

## ç³»çµ±éœ€æ±‚

### å¿…è¦å·¥å…·

- **Python 3.6+**ï¼ˆæ”¯æ´ JSON å’Œ subprocess æ¨¡çµ„ï¼‰
- **kubectl**ï¼ˆv1.18 æˆ–æ›´æ–°ç‰ˆæœ¬ï¼‰
  - éœ€è¦é…ç½®æ­£ç¢ºçš„ kubeconfig æŒ‡å‘ç›®æ¨™ GKE é›†ç¾¤
- **Google Cloud SDK**ï¼ˆå¯é¸ï¼Œå¦‚éœ€åŸ·è¡Œ gcloud å‘½ä»¤ï¼‰

### æ¬Šé™è¦æ±‚

åŸ·è¡Œæ­¤å·¥å…·éœ€è¦ä»¥ä¸‹ Kubernetes æ¬Šé™ï¼š

```yaml
- "get" on nodes
- "get" on pods (all namespaces)
- "get" on metrics.k8s.io
```

é€šå¸¸æƒ…æ³ä¸‹ï¼Œå…·æœ‰ä»¥ä¸‹è§’è‰²çš„ä½¿ç”¨è€…å¯ä»¥åŸ·è¡Œæ­¤å·¥å…·ï¼š

- `roles/container.admin`ï¼ˆå®Œæ•´ç®¡ç†å“¡ï¼‰
- `roles/container.viewer`ï¼ˆæª¢è¦–è€…ï¼‰+ metrics è®€å–æ¬Šé™

### ç¶²è·¯è¦æ±‚

- èƒ½é€£æ¥åˆ° GKE é›†ç¾¤çš„ Kubernetes API Server
- é›†ç¾¤å·²å®‰è£ Metrics Serverï¼ˆç”¨æ–¼æ”¶é›†è³‡æºä½¿ç”¨æ•¸æ“šï¼‰

---

## å®‰è£èˆ‡é…ç½®

### 1. æª¢æŸ¥ Python ç’°å¢ƒ

```bash
python3 --version
# é æœŸè¼¸å‡º: Python 3.6 æˆ–æ›´æ–°ç‰ˆæœ¬
```

### 2. é©—è­‰ kubectl é€£ç·š

```bash
kubectl cluster-info
kubectl auth can-i get pods --all-namespaces
```

å¦‚æœè¼¸å‡ºå‡ç‚º `yes`ï¼Œè¡¨ç¤ºæ¬Šé™é…ç½®æ­£ç¢ºã€‚


---

## å¿«é€Ÿé–‹å§‹

### åŸ·è¡Œå·¥å…·

```bash
python3 gke_resource_check.py
```

### é æœŸè¼¸å‡ºæ ¼å¼

å·¥å…·æœƒç”¢ç”Ÿä¸‰ä»½å ±å‘Šï¼š

1. **GKE æ±ºç­–å„€è¡¨æ¿** - æ± å±¤ç´šçš„æ‘˜è¦åˆ†æ
2. **ç¯€é»è©³ç´°æ•¸æ“š** - æ¯å€‹ç¯€é»çš„è³‡æºç‹€æ³
3. **é«˜é¢¨éšª Pod æ¸…å–®** - éœ€è¦é—œæ³¨çš„æ‡‰ç”¨ç¨‹å¼

### åŸ·è¡Œæ™‚é–“

- å°å‹é›†ç¾¤ï¼ˆ<10 ç¯€é»ï¼‰ï¼š5-10 ç§’
- ä¸­å‹é›†ç¾¤ï¼ˆ10-50 ç¯€é»ï¼‰ï¼š15-30 ç§’
- å¤§å‹é›†ç¾¤ï¼ˆ>50 ç¯€é»ï¼‰ï¼š30-60 ç§’

---

## å ±å‘Šè§£è®€

### å ±å‘Š 1ï¼šGKE æ±ºç­–å„€è¡¨æ¿

```
ğŸ“Š GKE æ±ºç­–å„€è¡¨æ¿ (Pool Decision Dashboard)
   ç›®æ¨™: è­˜åˆ¥æ˜¯å¦éœ€è¦ [æ›´æ›æ©Ÿå‹] æˆ– [æ“´å……æ•¸é‡]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
POOL NAME        | TYPE              | AVG CPU  | AVG MEM  | RECOMMENDATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
default-pool     | n2-standard-4     | 45%      | 72%      | ğŸ”§ å‡ç´šæ©Ÿå‹ (HighMem) â†’ n2-highmem-4
compute-pool     | n2-standard-8     | 82%      | 78%      | ğŸ“¦ æ“´å……ç¯€é» (Scale Out)
```

#### æ¬„ä½èªªæ˜

| æ¬„ä½ | èªªæ˜ |
|------|------|
| **POOL NAME** | Node Pool çš„åç¨± |
| **TYPE** | æ©Ÿå™¨é¡å‹ï¼Œæ ¼å¼ç‚º `<ç³»åˆ—>-<é¡å‹>-<æ ¸å¿ƒæ•¸>`ï¼ˆä¾‹ï¼šn2-standard-4ï¼‰ |
| **AVG CPU** | è©² Pool ä¸­æ‰€æœ‰ç¯€é»çš„å¹³å‡ CPU ä½¿ç”¨ç‡ |
| **AVG MEM** | è©² Pool ä¸­æ‰€æœ‰ç¯€é»çš„å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨ç‡ |
| **RECOMMENDATION** | æ¶æ§‹å¸«å»ºè­°è¡Œå‹• |

#### å»ºè­°è¡Œå‹•è§£é‡‹

| ç¬¦è™Ÿ | è¡Œå‹• | å«ç¾© | åŸå›  |
|------|------|------|------|
| âœ… | ç¶­æŒç¾ç‹€ | è³‡æºå‡è¡¡ | CPU å’Œè¨˜æ†¶é«”ä½¿ç”¨ç‡éƒ½åœ¨åˆç†ç¯„åœå…§ |
| ğŸ”§ | å‡ç´šæ©Ÿå‹ (HighMem) | æ›´æ›ç‚ºé«˜è¨˜æ†¶é«”æ©Ÿå™¨ | è¨˜æ†¶é«” >80% ä½† CPU <40%ï¼ˆè¨˜æ†¶é«”æˆç‚ºç“¶é ¸ï¼‰ |
| ğŸ”§ | å‡ç´šæ©Ÿå‹ (HighCPU) | æ›´æ›ç‚ºé«˜ CPU æ©Ÿå™¨ | CPU >80% ä½†è¨˜æ†¶é«” <40%ï¼ˆCPU æˆç‚ºç“¶é ¸ï¼‰ |
| ğŸ“¦ | æ“´å……ç¯€é» | å¢åŠ æ›´å¤šç¯€é»åˆ° Pool | CPU æˆ–è¨˜æ†¶é«” >75%ï¼ˆè³‡æºå³å°‡è€—ç›¡ï¼‰ |
| ğŸ“‰ | ç¸®æ¸›ç¯€é» | æ¸›å°‘ Pool ä¸­çš„ç¯€é»æ•¸ | CPU å’Œè¨˜æ†¶é«”éƒ½ <20%ï¼ˆè³‡æºæœªå……åˆ†åˆ©ç”¨ï¼‰ |

### å ±å‘Š 2ï¼šç¯€é»è©³ç´°æ•¸æ“š

```
ğŸ” ç¯€é»è©³ç´°æ•¸æ“š (Node Inspection)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NODE NAME                | POOL           | CPU USE  | MEM USE  | STATUS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
...gke-node-1            | default-pool   | 55%      | 68%      | ğŸŸ¢
...gke-node-2            | default-pool   | 62%      | 85%      | ğŸŸ  é«˜è² è¼‰
...gke-node-3            | default-pool   | 45%      | 92%      | ğŸ”´ OOMå±éšª
```

#### ç‹€æ…‹æŒ‡ç¤ºå™¨

| ç¬¦è™Ÿ | ç‹€æ…‹ | å«ç¾© | è¡Œå‹• |
|------|------|------|------|
| ğŸŸ¢ | å¥åº· | è¨˜æ†¶é«”ä½¿ç”¨ç‡ <80% | ç„¡éœ€ç«‹å³è¡Œå‹• |
| ğŸŸ  | é«˜è² è¼‰ | 80% â‰¤ è¨˜æ†¶é«”ä½¿ç”¨ç‡ â‰¤ 90% | ç›£æ¸¬ï¼Œæº–å‚™æ“´å…… |
| ğŸ”´ | OOMå±éšª | è¨˜æ†¶é«”ä½¿ç”¨ç‡ >90% | ç«‹å³æ¡å–è¡Œå‹• |

### å ±å‘Š 3ï¼šé«˜é¢¨éšª Pod æ¸…å–®

```
ğŸ”¥ é«˜é¢¨éšª Pod æ¸…å–® (High Risk Pods) - å·²æ’é™¤ç³»çµ±æœå‹™
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NAMESPACE       | POD NAME                      | MEM USE    | RISK TYPE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
production      | api-server-deploy-7f9c8b2a1  | 2048 Mi    | âš ï¸ Limit å‘Šæ€¥ (92%)
staging         | cache-worker-5d4e9f1b        | 1024 Mi    | âš ï¸ è¶…è³£ Burst (145%)
```

#### é¢¨éšªé¡å‹è§£é‡‹

| é¢¨éšªé¡å‹ | å‘Šè­¦ç´šåˆ¥ | è§£æ±ºæ–¹æ¡ˆ |
|---------|---------|---------|
| **âš ï¸ Limit å‘Šæ€¥** | é«˜ | Pod è¨˜æ†¶é«”ä½¿ç”¨å·²é”åˆ° Limit çš„ 85%ï¼Œå®¹æ˜“ OOMã€‚ä¿®æ”¹ YAML å¢åŠ  `limits.memory` |
| **âš ï¸ è¶…è³£ Burst** | ä¸­ | Pod è¨˜æ†¶é«”è¶…é Requestï¼Œç³»çµ±å¯èƒ½å°‡éå¤š Pod èª¿åº¦åˆ°åŒä¸€ç¯€é»ã€‚å¢åŠ  `requests.memory` |

---

## æ±ºç­–æŒ‡å—

### å ´æ™¯ 1ï¼šè¨˜æ†¶é«”ç“¶é ¸ï¼ˆå‡ç´šæ©Ÿå‹åˆ° HighMemï¼‰

**ç—‡ç‹€ï¼š**
- AVG MEM > 80%
- AVG CPU < 40%
- ç¯€é»ä¸Šæœ‰ Pod æ¥è¿‘è¨˜æ†¶é«” Limit

**è¡Œå‹•æ­¥é©Ÿï¼š**

1. å»ºç«‹æ–°çš„é«˜è¨˜æ†¶é«” Node Pool

```bash
gcloud container node-pools create highmem-pool \
  --cluster=<cluster-name> \
  --zone=<zone> \
  --machine-type=n2-highmem-4 \
  --enable-autoscaling \
  --min-nodes=2 \
  --max-nodes=10 \
  --disk-size=100
```

2. æ·»åŠ  Pod è¦ªå’Œæ€§æ¨™ç±¤ï¼ˆå¯é¸ï¼Œç”¨æ–¼æ§åˆ¶ Pod èª¿åº¦ï¼‰

```yaml
nodeSelector:
  cloud.google.com/gke-nodepool: highmem-pool
```

3. ç›£æ¸¬æ–°ç¯€é»ä¸Šçš„å·¥ä½œè² è¼‰é·ç§»

```bash
kubectl get nodes -l cloud.google.com/gke-nodepool=highmem-pool
```

4. ç¢ºèªç©©å®šå¾Œï¼Œå¯è€ƒæ…®ç¸®æ¸›èˆŠ Pool

```bash
gcloud container node-pools update default-pool \
  --enable-autoscaling \
  --min-nodes=1 \
  --max-nodes=3
```

### å ´æ™¯ 2ï¼šCPU ç“¶é ¸ï¼ˆå‡ç´šæ©Ÿå‹åˆ° HighCPUï¼‰

**ç—‡ç‹€ï¼š**
- AVG CPU > 80%
- AVG MEM < 40%
- ç¯€é»ä¸Šæœ‰ CPU å¯†é›†å‹çš„å·¥ä½œè² è¼‰

**è¡Œå‹•æ­¥é©Ÿï¼š**

1. å»ºç«‹æ–°çš„é«˜ CPU Node Pool

```bash
gcloud container node-pools create highcpu-pool \
  --cluster=<cluster-name> \
  --zone=<zone> \
  --machine-type=n2-highcpu-8 \
  --enable-autoscaling \
  --min-nodes=2 \
  --max-nodes=10
```

2. ç‚º CPU å¯†é›†å‹æ‡‰ç”¨æ·»åŠ ç¯€é»è¦ªå’Œæ€§

```yaml
nodeSelector:
  workload-type: cpu-intensive
```

3. åœ¨æ–°ç¯€é»ä¸Šæ‡‰ç”¨æ­¤æ¨™ç±¤

```bash
gcloud compute instances add-labels <node-name> \
  --labels=workload-type=cpu-intensive \
  --zone=<zone>
```

### å ´æ™¯ 3ï¼šè³‡æºä¸è¶³ï¼ˆæ“´å……ç¯€é»ï¼‰

**ç—‡ç‹€ï¼š**
- AVG CPU > 75% æˆ– AVG MEM > 75%
- ç„¡æ³•é€šéå‡ç´šæ©Ÿå‹è§£æ±ºï¼ˆå…©ç¨®è³‡æºéƒ½ç·Šå¼µï¼‰
- æ–° Pod ç„¡æ³•æˆåŠŸèª¿åº¦ï¼ˆpending ç‹€æ…‹ï¼‰

**è¡Œå‹•æ­¥é©Ÿï¼š**

1. å•Ÿç”¨æˆ–æ›´æ–° Node Pool è‡ªå‹•æ“´å±•

```bash
gcloud container node-pools update <pool-name> \
  --enable-autoscaling \
  --min-nodes=<current-size> \
  --max-nodes=<current-size * 2>
```

2. é©—è­‰è‡ªå‹•æ“´å±•æ˜¯å¦å•Ÿç”¨

```bash
gcloud container node-pools describe <pool-name> \
  --cluster=<cluster-name> \
  --format="value(autoscaling)"
```

3. ç›£æ¸¬æ“´å±•é€²åº¦

```bash
kubectl get nodes -w
# è§€å¯Ÿæ–°ç¯€é»åŠ å…¥
```

### å ´æ™¯ 4ï¼šè³‡æºæµªè²»ï¼ˆç¸®æ¸›ç¯€é»ï¼‰

**ç—‡ç‹€ï¼š**
- AVG CPU < 20% ä¸” AVG MEM < 20%
- å¤šå€‹ç¯€é»ä½¿ç”¨ç‡æ¥µä½
- é›†ç¾¤æˆæœ¬æŒçºŒä¸Šå‡

**è¡Œå‹•æ­¥é©Ÿï¼š**

1. èª¿æ•´è‡ªå‹•æ“´å±•çš„æœ€å°ç¯€é»æ•¸

```bash
gcloud container node-pools update <pool-name> \
  --enable-autoscaling \
  --min-nodes=2 \
  --max-nodes=5
```

2. Kubernetes æœƒè‡ªå‹•é©…é€ä½åˆ©ç”¨ç‡ç¯€é»ä¸Šçš„ Pod

```bash
# ç›£æ¸¬ Pod é‡æ–°èª¿åº¦
kubectl get pods -A -w | grep -E "(Pending|Running)"
```

3. ç¢ºèªç¯€é»å·²è¢«ç§»é™¤

```bash
gcloud compute instances list --filter="zone:<zone>" | grep <pool-name>
```

### å ´æ™¯ 5ï¼šé«˜é¢¨éšª Pod çš„è¶…è³£ï¼ˆBurstï¼‰

**ç—‡ç‹€ï¼š**
- Pod è¨˜æ†¶é«”ä½¿ç”¨é‡è¶…é Requestï¼ˆå¦‚ Request: 512Miï¼Œå¯¦éš›: 768Miï¼‰
- é¢¨éšªæç¤ºï¼šâš ï¸ è¶…è³£ Burst (145%)

**è¡Œå‹•æ­¥é©Ÿï¼š**

1. æª¢æŸ¥ Pod çš„ç•¶å‰é…ç½®

```bash
kubectl get pod <pod-name> -n <namespace> -o yaml | grep -A 5 "resources:"
```

2. ä¿®æ”¹ Pod çš„ Request å€¼

```yaml
resources:
  requests:
    memory: "768Mi"      # æé«˜ Request
    cpu: "250m"
  limits:
    memory: "1Gi"        # ä¿æŒ Limit
    cpu: "500m"
```

3. æ»¾å‹•æ›´æ–°æ‡‰ç”¨

```bash
kubectl rollout restart deployment/<deployment-name> -n <namespace>
```

4. é©—è­‰èª¿æ•´æ•ˆæœ

```bash
# ç­‰å¾… 30 ç§’å¾Œé‡æ–°åŸ·è¡Œå·¥å…·
python3 gke_resource_check.py
```

---

## é…ç½®èª¿æ•´

### ä¿®æ”¹æ±ºç­–é–¾å€¼

ç·¨è¼¯ `gke_resource_check.py` ä¸­çš„ `THRESHOLDS` å­—å…¸ä»¥é©æ‡‰ä½ çš„æ¥­å‹™éœ€æ±‚ï¼š

```python
THRESHOLDS = {
    "mem_upgrade": 80,              # è¨˜æ†¶é«”å‡ç´šé–¾å€¼ï¼ˆé è¨­ 80%ï¼‰
    "cpu_upgrade": 80,              # CPU å‡ç´šé–¾å€¼ï¼ˆé è¨­ 80%ï¼‰
    "scale_out": 75,                # æ“´å……ç¯€é»é–¾å€¼ï¼ˆé è¨­ 75%ï¼‰
    "scale_in": 20,                 # ç¸®æ¸›ç¯€é»é–¾å€¼ï¼ˆé è¨­ 20%ï¼‰
    "cpu_crossover": 40,            # CPU é–’ç½®é–¾å€¼ï¼ˆé è¨­ 40%ï¼‰
    "mem_crossover": 40,            # è¨˜æ†¶é«”é–’ç½®é–¾å€¼ï¼ˆé è¨­ 40%ï¼‰
    "pod_limit_critical": 85,       # Pod Limit å‘Šè­¦ï¼ˆé è¨­ 85%ï¼‰
    "pod_burst_critical": 100,      # Pod è¶…è³£å‘Šè­¦ï¼ˆé è¨­ 100%ï¼‰
    "node_oom_danger": 90,          # OOM å±éšªé–¾å€¼ï¼ˆé è¨­ 90%ï¼‰
    "node_high_load": 80,           # é«˜è² è¼‰é–¾å€¼ï¼ˆé è¨­ 80%ï¼‰
}
```

### æ’é™¤ç‰¹å®š Namespace

ç·¨è¼¯ `EXCLUDED_NAMESPACES` åˆ—è¡¨ä»¥æ’é™¤ç³»çµ±æˆ–éæ¥­å‹™ç›¸é—œçš„ Podï¼š

```python
EXCLUDED_NAMESPACES = [
    "kube-system",
    "gke-managed-system",
    "istio-system",
    "gmp-system",
    "my-system-namespace",  # è‡ªè¨‚æ’é™¤
]
```

### èª¿æ•´ kubectl è¶…æ™‚

å¦‚æœé›†ç¾¤è¼ƒå¤§æˆ–ç¶²è·¯è¼ƒæ…¢ï¼Œå¯å¢åŠ è¶…æ™‚æ™‚é–“ï¼š

```python
KUBECTL_TIMEOUT = 60  # å¾ 30 ç§’å¢åŠ åˆ° 60 ç§’
```

---

## å¸¸è¦‹å•é¡Œ

### Q1ï¼šå·¥å…·é¡¯ç¤ºã€Œâš ï¸ è­¦å‘Š: å‘½ä»¤å¤±æ•—ã€ï¼Ÿ

**åŸå› ï¼š** kubectl å‘½ä»¤åŸ·è¡Œå¤±æ•—ï¼Œé€šå¸¸æ˜¯ kubeconfig é…ç½®å•é¡Œã€‚

**è§£æ±ºæ–¹æ¡ˆï¼š**

```bash
# æª¢æŸ¥ kubeconfig
kubectl config current-context

# å¦‚æœä¸æ­£ç¢ºï¼Œåˆ‡æ›åˆ°æ­£ç¢ºçš„é›†ç¾¤
kubectl config use-context <cluster-context>

# é©—è­‰é€£ç·š
kubectl cluster-info
```

### Q2ï¼šç‚ºä»€éº¼ Pod æ¸…å–®æ˜¯ç©ºçš„ï¼Ÿ

**åŸå› ï¼š** å¯èƒ½æ˜¯ Metrics Server æœªå®‰è£æˆ– Pod éƒ½åœ¨æ’é™¤çš„ Namespace ä¸­ã€‚

**è§£æ±ºæ–¹æ¡ˆï¼š**

```bash
# æª¢æŸ¥ Metrics Server
kubectl get deployment metrics-server -n kube-system

# æª¢æŸ¥æ˜¯å¦æœ‰éç³»çµ± Pod
kubectl get pods -A --exclude-namespaces=kube-system,istio-system,gke-managed-system
```

### Q3ï¼šã€Œå‡ç´šæ©Ÿå‹ã€å’Œã€Œæ“´å……ç¯€é»ã€å¦‚ä½•é¸æ“‡ï¼Ÿ

**ä½¿ç”¨æ±ºç­–æ¨¹ï¼š**

1. æª¢æŸ¥ AVG CPU å’Œ AVG MEM
2. å¦‚æœ**åªæœ‰ä¸€ç¨®è³‡æº**ä½¿ç”¨ç‡é«˜ï¼ˆ>80%ï¼‰ï¼Œå¦ä¸€ç¨®ä½ï¼ˆ<40%ï¼‰â†’ **å‡ç´šæ©Ÿå‹**
3. å¦‚æœ**å…©ç¨®è³‡æº**éƒ½é«˜ï¼ˆ>75%ï¼‰â†’ **æ“´å……ç¯€é»**
4. å¦‚æœ**å…©ç¨®è³‡æº**éƒ½ä½ï¼ˆ<20%ï¼‰â†’ **ç¸®æ¸›ç¯€é»**

### Q4ï¼šç‚ºä»€éº¼å»ºè­°ã€Œå‡ç´šæ©Ÿå‹ (HighMem) â†’ n2-highmem-4ã€ï¼Ÿ

**èªªæ˜ï¼š**
- `n2` æ˜¯æ©Ÿå™¨ç³»åˆ—
- `highmem` æ˜¯æ–°çš„æ©Ÿå™¨é¡å‹ï¼ˆè¨˜æ†¶é«”æ›´å¤šï¼ŒCPU è¼ƒå°‘ï¼‰
- `4` æ˜¯æ ¸å¿ƒæ•¸é‡ï¼ˆä¿æŒä¸è®Šï¼‰

å¯é¸æ“‡ç›¸åŒæˆ–æ›´é«˜çš„æ ¸å¿ƒæ•¸ã€‚

### Q5ï¼šæˆ‘çš„é›†ç¾¤æ²’æœ‰ Metrics Serverï¼Œæœƒæ€æ¨£ï¼Ÿ

**å½±éŸ¿ï¼š**
- CPU å’Œè¨˜æ†¶é«”ä½¿ç”¨ç‡é¡¯ç¤ºç‚º 0%
- ç„¡æ³•çœ‹åˆ°ã€ŒCPU USEã€å’Œã€ŒMEM USEã€æ¬„ä½
- æ±ºç­–å»ºè­°ä»æœƒåŸºæ–¼ Pod Request/Limit é€²è¡Œ

**è§£æ±ºæ–¹æ¡ˆï¼š**

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

---

## æ•…éšœæ’é™¤

### æ•…éšœ 1ï¼š`kubectl: command not found`

**ç—‡ç‹€ï¼š** åŸ·è¡Œ python è…³æœ¬å¾Œç«‹å³å ±éŒ¯

**è§£æ±ºæ–¹æ¡ˆï¼š**

```bash
# å®‰è£ kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/amd64/kubectl"

# æˆ–ä½¿ç”¨åŒ…ç®¡ç†å·¥å…·
brew install kubectl  # macOS
apt-get install kubectl  # Ubuntu/Debian
```

### æ•…éšœ 2ï¼š`json.JSONDecodeError`

**ç—‡ç‹€ï¼š** è§£æ JSON å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒ

**è§£æ±ºæ–¹æ¡ˆï¼š**

```bash
# æª¢æŸ¥ kubectl è¼¸å‡ºæ ¼å¼
kubectl get nodes -o json | jq .

# å¦‚æœå‡ºéŒ¯ï¼Œæ›´æ–° kubectl
kubectl version --client
```

### æ•…éšœ 3ï¼šç„¡æ³•é€£æ¥åˆ° API Server

**ç—‡ç‹€ï¼š** é¡¯ç¤ºã€Œç„¡æ³•å–å¾— Node è³‡è¨Šã€

**è§£æ±ºæ–¹æ¡ˆï¼š**

```bash
# æª¢æŸ¥ç¶²è·¯é€£ç·š
ping <api-server-host>

# æª¢æŸ¥èªè­‰
kubectl auth can-i get nodes

# æª¢æŸ¥ kubeconfig çš„æœ‰æ•ˆæ€§
kubectl config view
```

### æ•…éšœ 4ï¼šæ¬Šé™ä¸è¶³

**ç—‡ç‹€ï¼š** ã€ŒUser cannot get nodesã€

**è§£æ±ºæ–¹æ¡ˆï¼š**

```bash
# æˆäºˆå¿…è¦è§’è‰²
gcloud projects add-iam-policy-binding <project-id> \
  --member=user:<email> \
  --role=roles/container.viewer

# æˆ–æ›´æ–° RBAC
kubectl create clusterrolebinding <name> \
  --clusterrole=view \
  --serviceaccount=default:default
```

### æ•…éšœ 5ï¼šåŸ·è¡Œç·©æ…¢æˆ–è¶…æ™‚

**ç—‡ç‹€ï¼š** å·¥å…·åŸ·è¡Œè¶…é 2 åˆ†é˜ä»æœªå®Œæˆ

**è§£æ±ºæ–¹æ¡ˆï¼š**

```python
# å¢åŠ è¶…æ™‚æ™‚é–“
KUBECTL_TIMEOUT = 60  # æ”¹ç‚º 60 ç§’

# æˆ–æ¸›å°‘ retry æ¬¡æ•¸
KUBECTL_RETRY_COUNT = 0
```

---

## é€²éšä½¿ç”¨

### è‡ªå‹•åŒ–å®šæœŸæª¢æŸ¥

ä½¿ç”¨ Cron å®šæœŸåŸ·è¡Œæª¢æŸ¥ä¸¦å°‡çµæœä¿å­˜ç‚ºæ—¥èªŒï¼š

```bash
#!/bin/bash
# save_gke_report.sh

REPORT_DIR="/var/log/gke-reports"
mkdir -p $REPORT_DIR

TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
OUTPUT_FILE="$REPORT_DIR/gke_report_${TIMESTAMP}.txt"

python3 /path/to/gke_resource_check.py > $OUTPUT_FILE 2>&1

# è¨­ç½® Cron jobï¼ˆæ¯å¤©ä¸Šåˆ 8 é»ï¼‰
# 0 8 * * * /path/to/save_gke_report.sh
```

### é›†æˆåˆ° Slack é€šçŸ¥

å°‡å ±å‘Šç™¼é€åˆ° Slack é »é“ï¼š

```bash
#!/bin/bash
# send_to_slack.sh

SLACK_WEBHOOK="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

MESSAGE=$(python3 /path/to/gke_resource_check.py)

curl -X POST -H 'Content-type: application/json' \
  --data "$(echo $MESSAGE | jq -Rs '{text: .}')" \
  $SLACK_WEBHOOK
```

### èˆ‡ç›£æ¸¬ç³»çµ±é›†æˆ

å°‡æ•¸æ“šå°å‡ºç‚º JSON ä¾›å…¶ä»–ç³»çµ±ä½¿ç”¨ï¼š

```bash
# ä¿®æ”¹è…³æœ¬æœ€å¾Œéƒ¨åˆ†ï¼Œæ·»åŠ  JSON è¼¸å‡º
python3 -c "
import json
import subprocess

# ... åŸ·è¡Œæ”¶é›†é‚è¼¯ ...

output = {
    'pools': [...],
    'nodes': [...],
    'risky_pods': [...]
}

with open('/tmp/gke_metrics.json', 'w') as f:
    json.dump(output, f)
"
```

---

## æ”¯æ´èˆ‡åé¥‹

å¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œè«‹ï¼š

1. æª¢æŸ¥ [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤) éƒ¨åˆ†
2. æª¢æŸ¥ kubectl å’Œ Metrics Server çš„å®‰è£ç‹€æ…‹
3. æŸ¥çœ‹ Kubernetes å®˜æ–¹æ–‡æª”ï¼šhttps://kubernetes.io/docs/
4. æŸ¥çœ‹ GKE å®˜æ–¹æ–‡æª”ï¼šhttps://cloud.google.com/kubernetes-engine/docs

---

## è®Šæ›´æ—¥èªŒ

**ç‰ˆæœ¬ 1.0**ï¼ˆåˆå§‹ç‰ˆæœ¬ï¼‰
- æ”¯æ´ Pool æ±ºç­–å„€è¡¨æ¿
- æ”¯æ´ç¯€é»è©³ç´°æ•¸æ“šæª¢æŸ¥
- æ”¯æ´é«˜é¢¨éšª Pod è­˜åˆ¥
- æ”¯æ´è¨˜æ†¶é«”å’Œ CPU ä½¿ç”¨ç‡åˆ†æ

---
